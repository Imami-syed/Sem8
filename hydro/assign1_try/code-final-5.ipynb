{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import gamma, norm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_SPI(data):\n",
    "    temp_data = pd.to_numeric(data, errors='coerce')\n",
    "    temp_data = np.clip(temp_data, 1e-15, None)\n",
    "    mask = np.isfinite(temp_data)\n",
    "    temp_data = temp_data[mask]\n",
    "\n",
    "    shape, loc, scale = gamma.fit(temp_data, floc=0)\n",
    "\n",
    "    cdf = gamma.cdf(temp_data, shape, loc=0, scale=scale)\n",
    "    spi = norm.ppf(cdf) \n",
    "\n",
    "    spi = (spi - np.mean(spi))/np.std(spi)\n",
    "    return spi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "l = []\n",
    "def list_files(directory):\n",
    "    files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, file)):\n",
    "            files.append(file)\n",
    "    return files\n",
    "\n",
    "l = list_files('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_start_month = 1\n",
    "global_start_year = 2015\n",
    "global_end_month = 1\n",
    "global_end_year = 2019\n",
    "\n",
    "\n",
    "month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
    "             'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "\n",
    "# SPI_df = pd.DataFrame(columns=[\"Station Name\", \"Latitude\", \"Longitude\", \"Avg SPI\"])\n",
    "\n",
    "def yearWiseCalculation(start_month,start_year,end_month,end_year, SPI_Type, make_plot=False):\n",
    "    SPI_arr = []\n",
    "\n",
    "    for files in l:\n",
    "    # print(files)\n",
    "\n",
    "        station_name, LatLong = files.strip('.csv').split('-')\n",
    "        Lat, Long = LatLong.split(',')\n",
    "        Lat = float(Lat.strip())\n",
    "        Long = float(Long.strip())\n",
    "\n",
    "        temp_df = pd.read_csv(os.path.join('data', files), header=1)\n",
    "        dates = temp_df['Dates'].values\n",
    "        # print(dates)\n",
    "        # print(start_date, end_date)\n",
    "        temp_df[['Month', 'Year']] = temp_df['Dates'].str.split('-', expand=True)\n",
    "        temp_df['Year'] = temp_df['Year'].astype(int)\n",
    "        temp_df['value'] = temp_df['ACTUAL (mm) ']\n",
    "        temp_df['Month_num'] = temp_df['Month'].map(month_map)\n",
    "        # print(temp_df.iloc[0]['Year'], temp_df.iloc[0]['Month'])\n",
    "        # print(temp_df.iloc[0]['Year'], temp_df.iloc[0]['Month_num'])\n",
    "        # print(temp_df.iloc[-1]['Year'], temp_df.iloc[-1]['Month_num'])\n",
    "        if(temp_df.iloc[0]['Year']*12 + temp_df.iloc[0]['Month_num'] > start_year*12 + start_month):\n",
    "            continue\n",
    "        elif(temp_df.iloc[-1]['Year']*12 + temp_df.iloc[-1]['Month_num'] < end_year * 12 + end_month):\n",
    "            continue\n",
    "\n",
    "        temp_df['Date'] = pd.to_datetime(temp_df['Dates'], format='%b-%Y')\n",
    "\n",
    "        # Set 'Date' column as the index\n",
    "        temp_df.set_index('Date', inplace=True)\n",
    "\n",
    "        start_date = datetime(global_start_year, global_start_month, 1)\n",
    "        end_date = datetime(global_end_year, global_end_month, 1)\n",
    "\n",
    "        # Create a complete date range spanning from the minimum to maximum date in the DataFrame\n",
    "        complete_date_range = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "\n",
    "        # Reindex the DataFrame with the complete date range\n",
    "        temp_df = temp_df.reindex(complete_date_range, fill_value=0)\n",
    "\n",
    "        # Reset index to make 'Date' a column again\n",
    "        temp_df.reset_index(inplace=True)\n",
    "\n",
    "        # Rename 'index' column to 'Date'\n",
    "        temp_df.rename(columns={'index': 'Date'}, inplace=True)\n",
    "        # Convert 'Date' back to the original format (if needed)\n",
    "        temp_df['Dates'] = temp_df['Date'].dt.strftime('%b-%Y')\n",
    "        # print(temp_df['Dates'])\n",
    "        \n",
    "\n",
    "        temp_df[['Month', 'Year']] = temp_df['Dates'].str.split('-', expand=True)\n",
    "        temp_df['Year'] = temp_df['Year'].astype(int)\n",
    "        temp_df['value'] = temp_df['ACTUAL (mm) ']\n",
    "        temp_df['Month_num'] = temp_df['Month'].map(month_map)\n",
    "        \n",
    "        temp_df = temp_df.drop(columns=\"ACTUAL (mm) \")\n",
    "\n",
    "        rainfall_data = temp_df[\"value\"].to_numpy()\n",
    "        rainfall_final_data = temp_df[\"value\"].to_numpy()\n",
    "        rainfall_data = np.convolve(rainfall_data, np.ones(SPI_Type)/SPI_Type, mode='same')\n",
    "        spi_values = calculate_SPI(rainfall_data)\n",
    "\n",
    "        filtered_df_condition = ((temp_df['Year'] > start_year) | \n",
    "                            ((temp_df['Year'] == start_year) & (temp_df['Month_num'] >= start_month))) & ((temp_df['Year'] < end_year) |\n",
    "                            ((temp_df['Year'] == end_year) & (temp_df['Month_num'] <= end_month)))\n",
    "\n",
    "        first_idx = filtered_df_condition.idxmax()\n",
    "        last_idx = filtered_df_condition[::-1].idxmax()     \n",
    "        \n",
    "        print(first_idx, last_idx)\n",
    "        spi_filtered_values = spi_values[first_idx:last_idx+1]\n",
    "        rainfall_final_filtered = rainfall_final_data[first_idx:last_idx+1]\n",
    "\n",
    "        # average_spi = np.mean(spi_range)\n",
    "        # filtered_df = temp_df[first_idx:last_idx+1]\n",
    "        filtered_df = temp_df[first_idx:last_idx+1].copy()\n",
    "        filtered_df['SPI'] = spi_filtered_values\n",
    "        starting_date = start_date.strftime('%b-%Y')\n",
    "        ending_date = end_date.strftime('%b-%Y')\n",
    "        \n",
    "        # FOR longest duration of drought\n",
    "        avg_spi = np.mean(filtered_df['SPI'])\n",
    "        mask = (spi_filtered_values < 0)\n",
    "        longest_drought = 0\n",
    "        current_drought = 0\n",
    "        longest_drought_start = 0\n",
    "        current_drought_start = 0\n",
    "        for i, is_drought in enumerate(mask):\n",
    "            if(is_drought):\n",
    "                current_drought += 1\n",
    "                if(current_drought == 1):\n",
    "                    current_drought_start = i\n",
    "                if(current_drought > longest_drought):\n",
    "                    longest_drought = current_drought\n",
    "                    longest_drought_start = current_drought_start\n",
    "            else:\n",
    "                current_drought = 0\n",
    "        \n",
    "        longest_drought_period = (longest_drought_start, longest_drought_start + longest_drought)\n",
    "        print(f'Longest drought duration: {longest_drought} months')\n",
    "        \n",
    "        # print(starting_date, ending_date)\n",
    "        # print(dates)\n",
    "        # print(temp_df.iloc[0]['Year'], temp_df.iloc[0]['Month'])\n",
    "        index1 = np.where(dates==starting_date)[0]\n",
    "        index2 = np.where(dates==ending_date)[0]\n",
    "        # many dates arrays dont have the starting date and ending date entered by the user\n",
    "        if(index1.size == 0 or index2.size == 0):\n",
    "            # continue\n",
    "            # print(dates)\n",
    "            # Convert date strings to datetime objects\n",
    "            date_objs = [datetime.strptime(date_str, '%b-%Y') for date_str in dates]\n",
    "\n",
    "            # Convert starting_date and ending_date strings to datetime objects\n",
    "            starting_date_obj = datetime.strptime(starting_date, '%b-%Y')\n",
    "            ending_date_obj = datetime.strptime(ending_date, '%b-%Y')\n",
    "\n",
    "            # Find the indices of the first date after the starting date\n",
    "            index1 = next((i for i, date_obj in enumerate(date_objs) if date_obj > starting_date_obj), None)\n",
    "\n",
    "            # Find the indices of the last date before the ending date\n",
    "            index2 = next((i for i, date_obj in reversed(list(enumerate(date_objs))) if date_obj < ending_date_obj), None)\n",
    "\n",
    "            # find first date in dates after starting date\n",
    "            # index1 = np.where(dates > starting_date)[0]\n",
    "            # find first date in dates before ending date\n",
    "            # index2 = np.where(dates < ending_date)[0]\n",
    "            # SPI_arr.append([station_name, Lat, Long, np.average(filtered_df['SPI']), 0])\n",
    "            # continue\n",
    "        else:\n",
    "            index1 = index1[0]\n",
    "            index2 = index2[0]\n",
    "\n",
    "        # print(index1[0], index2[0])\n",
    "        index1 =index1 - SPI_Type + 1\n",
    "        index2 = index2 - SPI_Type + 1\n",
    "        # print(index1, index2)\n",
    "        spi_range = spi_values[index1:index2+1]\n",
    "\n",
    "        drought_frequency = 0\n",
    "        consecutive_negatives = 0\n",
    "\n",
    "        drought_frequency = np.sum(spi_range < 0)\n",
    "\n",
    "        if(make_plot):\n",
    "            plt.figure(figsize=(20,12))\n",
    "            plt.title(station_name)\n",
    "            plt.plot(filtered_df['Dates'], filtered_df['SPI'])\n",
    "            plt.xticks(filtered_df['Dates'], rotation=90)\n",
    "            plt.ylim(-max(abs(filtered_df['SPI'])+2), max(abs(filtered_df['SPI'])+2))\n",
    "            plt.fill_between(filtered_df['Dates'], filtered_df['SPI'], where=(filtered_df['SPI'] > 0), color='blue', alpha=0.5, label='Positive SPI')\n",
    "            plt.fill_between(filtered_df['Dates'], filtered_df['SPI'], where=(filtered_df['SPI'] <= 0), color='red', alpha=0.5, label='Negative SPI')\n",
    "            if longest_drought > 0:\n",
    "                plt.fill_between(filtered_df['Dates'][longest_drought_period[0]:longest_drought_period[1]], filtered_df['SPI'][longest_drought_period[0]:longest_drought_period[1]], where=(filtered_df['SPI'][longest_drought_period[0]:longest_drought_period[1]] <= 0), color='green', alpha=0.5, label='Longest Drought Period')\n",
    "            # legend \n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        # SPI_df.iloc[len(SPI_df.index)] = [station_name, Lat, Long, np.average(filtered_df['SPI'])]\n",
    "        SPI_arr.append([station_name, Lat, Long, np.average(filtered_df['SPI']), drought_frequency, np.mean(rainfall_final_filtered)])\n",
    "    return SPI_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin, Affine\n",
    "\n",
    "\n",
    "def interpolate_grid(SPI_df):\n",
    "    area_of_interest = gpd.read_file(\"final-basin.gpkg\")\n",
    "\n",
    "\n",
    "    xmin, ymin, xmax, ymax = area_of_interest.total_bounds\n",
    "    # print(xmin, ymin, xmax, ymax)\n",
    "    grid_x, grid_y = np.meshgrid(np.linspace(xmin, xmax, num=100), np.linspace(ymin, ymax, num=100))\n",
    "\n",
    "    grid_z = griddata((SPI_df['Longitude'], SPI_df['Latitude']), SPI_df['Avg SPI'], (grid_x, grid_y), method='cubic')\n",
    "    spi_value_layer=grid_z\n",
    "    \n",
    "    interpolated_grid = gpd.GeoDataFrame(\n",
    "        {'value': grid_z.flatten()},\n",
    "        geometry=gpd.points_from_xy(grid_x.flatten(), grid_y.flatten()), crs=area_of_interest.crs\n",
    "    )\n",
    "    clipped_interpolated_grid = gpd.clip(interpolated_grid, area_of_interest)\n",
    "\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    area_of_interest.plot(figsize=(12, 8), color='white', edgecolor='black')\n",
    "    clipped_interpolated_grid.plot(column='value',  ax=plt.gca(), legend=True)\n",
    "    plt.scatter(SPI_df['Longitude'], SPI_df['Latitude'], c=SPI_df['Avg SPI'], edgecolor='black', label='Data Points')\n",
    "\n",
    "    for i, txt in enumerate(SPI_df['Station Name']):\n",
    "        plt.annotate(txt, (SPI_df['Longitude'].iloc[i], SPI_df['Latitude'].iloc[i]), fontsize=8, ha='left')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    final_df = pd.DataFrame({\n",
    "        'SPI': spi_value_layer.flatten(),\n",
    "    })\n",
    "\n",
    "    # final_df = final_df.dropna(subset=['SPI'])\n",
    "    # final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "    output_file_name = 'SPI_raster.tif'\n",
    "\n",
    "    number_of_rows = spi_value_layer.shape[0]\n",
    "    number_of_columns = spi_value_layer.shape[1]\n",
    "\n",
    "    left, right = grid_x.min(), grid_x.max()\n",
    "    bottom, top = grid_y.min(), grid_y.max()\n",
    "\n",
    "    # print(grid_y)\n",
    "    resolution_x = 0.032\n",
    "    resolution_y = 0.026\n",
    "\n",
    "    # print(grid_x)\n",
    "    transform = from_origin(left, bottom, resolution_x, -resolution_y) # negative sign in y to flip in the y direction\n",
    "\n",
    "    # transform = Affine(resolution, 0, left, 0, -resolution, top)\n",
    "\n",
    "    options = {\n",
    "        'driver': 'GTiff',\n",
    "        'dtype': final_df['SPI'].dtype,\n",
    "        'width': number_of_columns,\n",
    "        'height': number_of_rows,\n",
    "        'count': 1,\n",
    "        'crs': 'EPSG:4326',\n",
    "        'transform': transform,\n",
    "        'nodata': np.nan\n",
    "    }\n",
    "\n",
    "    with rasterio.open(output_file_name, 'w', **options) as output_file:\n",
    "        output_file.write(spi_value_layer, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_avg_rainfall(SPI_df):\n",
    "    area_of_interest = gpd.read_file(\"final-basin.gpkg\")\n",
    "\n",
    "\n",
    "    xmin, ymin, xmax, ymax = area_of_interest.total_bounds\n",
    "    # print(xmin, ymin, xmax, ymax)\n",
    "    grid_x, grid_y = np.meshgrid(np.linspace(xmin, xmax, num=100), np.linspace(ymin, ymax, num=100))\n",
    "\n",
    "    grid_z = griddata((SPI_df['Longitude'], SPI_df['Latitude']), SPI_df['Rainfall'], (grid_x, grid_y), method='cubic')\n",
    "    spi_value_layer=grid_z\n",
    "    \n",
    "    interpolated_grid = gpd.GeoDataFrame(\n",
    "        {'value': grid_z.flatten()},\n",
    "        geometry=gpd.points_from_xy(grid_x.flatten(), grid_y.flatten()), crs=area_of_interest.crs\n",
    "    )\n",
    "    clipped_interpolated_grid = gpd.clip(interpolated_grid, area_of_interest)\n",
    "\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    area_of_interest.plot(figsize=(12, 8), color='white', edgecolor='black')\n",
    "    clipped_interpolated_grid.plot(column='value',  ax=plt.gca(), legend=True)\n",
    "    plt.scatter(SPI_df['Longitude'], SPI_df['Latitude'], c=SPI_df['Rainfall'], edgecolor='black', label='Data Points')\n",
    "\n",
    "    for i, txt in enumerate(SPI_df['Station Name']):\n",
    "        plt.annotate(txt, (SPI_df['Longitude'].iloc[i], SPI_df['Latitude'].iloc[i]), fontsize=8, ha='left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "import geopandas as gpd\n",
    "\n",
    "def drought_frequency(SPI_df):\n",
    "    area_of_interest = gpd.read_file(\"final-basin.gpkg\")\n",
    "\n",
    "    xmin, ymin, xmax, ymax = area_of_interest.total_bounds\n",
    "    # print(xmin, ymin, xmax, ymax)\n",
    "    grid_x, grid_y = np.meshgrid(np.linspace(xmin, xmax, num=100), np.linspace(ymin, ymax, num=100))\n",
    "\n",
    "    grid_z = griddata((SPI_df['Longitude'], SPI_df['Latitude']), SPI_df['Drought Frequency'], (grid_x, grid_y), method='nearest')\n",
    "    interpolated_grid = gpd.GeoDataFrame(\n",
    "        {'value': grid_z.flatten()},\n",
    "        geometry=gpd.points_from_xy(grid_x.flatten(), grid_y.flatten()), crs=area_of_interest.crs\n",
    "    )\n",
    "    clipped_interpolated_grid = gpd.clip(interpolated_grid, area_of_interest)\n",
    "\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    area_of_interest.plot(figsize=(12, 8), color='white', edgecolor='black')\n",
    "    clipped_interpolated_grid.plot(column='value',  ax=plt.gca(), legend=True)\n",
    "    plt.scatter(SPI_df['Longitude'], SPI_df['Latitude'], c=SPI_df['Drought Frequency'], edgecolor='black', label='Data Points')\n",
    "\n",
    "    for i, txt in enumerate(SPI_df['Station Name']):\n",
    "        plt.annotate(txt, (SPI_df['Longitude'].iloc[i], SPI_df['Latitude'].iloc[i]), fontsize=8, ha='left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "def areaOfExtent(SPI_df):\n",
    "    area_of_interest = gpd.read_file(\"final-basin.gpkg\")\n",
    "\n",
    "    xmin, ymin, xmax, ymax = area_of_interest.total_bounds\n",
    "    grid_x, grid_y = np.meshgrid(np.linspace(xmin, xmax, num=100), np.linspace(ymin, ymax, num=100))\n",
    "\n",
    "    # Calculate drought frequency\n",
    "    grid_z_frequency = griddata((SPI_df['Longitude'], SPI_df['Latitude']), SPI_df['Avg SPI'], (grid_x, grid_y), method='cubic')\n",
    "    interpolated_grid_frequency = gpd.GeoDataFrame(\n",
    "        {'frequency': grid_z_frequency.flatten()},\n",
    "        geometry=gpd.points_from_xy(grid_x.flatten(), grid_y.flatten()), crs=area_of_interest.crs\n",
    "    )\n",
    "    clipped_interpolated_grid_frequency = gpd.clip(interpolated_grid_frequency, area_of_interest)\n",
    "\n",
    "\n",
    "    # print(grid_z_frequency)\n",
    "    # # Calculate drought areal extent\n",
    "    \n",
    "    \n",
    "    count=0\n",
    "    drought=0\n",
    "\n",
    "    for i in grid_z_frequency:\n",
    "        for j in i:\n",
    "            # print(j)\n",
    "            if(np.isnan(j)!=True):\n",
    "                count+=1\n",
    "                if(j<0):\n",
    "                    drought+=1                \n",
    "\n",
    "    \n",
    "    return drought/count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_month = int(input(\"Enter start month: \"))\n",
    "start_year = int(input(\"Enter start year: \"))\n",
    "end_month = int(input(\"Enter end month: \"))\n",
    "end_year = int(input(\"Enter End Year: \"))\n",
    "SPI_Type = int(input(\"Enter SPI Value: \"))\n",
    "\n",
    "user_start_year = start_year\n",
    "\n",
    "# %%\n",
    "print(start_month, start_year, end_month, end_year)\n",
    "\n",
    "SPI_arr = yearWiseCalculation(start_month,start_year,end_month,end_year, SPI_Type, make_plot=True)\n",
    "\n",
    "SPI_df = pd.DataFrame(SPI_arr, columns=[\"Station Name\", \"Latitude\", \"Longitude\", \"Avg SPI\", \"Drought Frequency\", \"Rainfall\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areaOfExtent(SPI_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPI_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Rainfall in the selected timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_avg_rainfall(SPI_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drought frequency interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_frequency(SPI_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial interpolation of SPI Values  (Intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_grid(SPI_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Areal Extent for the current timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Arial extent (No of cells with SPI<0 / total no of cells): ', areaOfExtent(SPI_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arial Extent per year in the selected timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have calculated areal extent values and stored them in a list called 'areal_extent_values' for each year\n",
    "\n",
    "start_month = 1\n",
    "end_month = 12\n",
    "years = range(user_start_year,end_year+1)\n",
    "\n",
    "areal_extent_values = []\n",
    "\n",
    "# Loop through each year and calculate areal extent\n",
    "for start_year in years:\n",
    "    SPI_arr = yearWiseCalculation(start_month, start_year, end_month, start_year, SPI_Type)\n",
    "    SPI_df = pd.DataFrame(SPI_arr, columns=[\"Station Name\", \"Latitude\", \"Longitude\", \"Avg SPI\", \"Drought Frequency\", \"Rainfall\"])\n",
    "    areal_extent = areaOfExtent(SPI_df)\n",
    "    if(start_year == 2019):\n",
    "        print(areal_extent)\n",
    "    areal_extent_values.append(areal_extent)\n",
    "\n",
    "# Plotting the bar graph\n",
    "\n",
    "print(areal_extent_values)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(years, areal_extent_values, color='blue')\n",
    "plt.title(\"Areal Extent of Drought Over Years\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Areal Extent\")\n",
    "plt.xticks(years)  # Ensure all years are displayed on the x-axis\n",
    "plt.grid(axis='y')  # Add gridlines for better readability\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
